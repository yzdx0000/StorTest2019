# -*- coding:utf-8 _*-
"""
测试内容:一节点所有数据盘故障，部分超时内恢复

步骤:
1、在节点A创建LUN1-LUN6
2、将逻辑卷映射至主机1上LUN1-LUN6
3、在主机1上运行vdbench -f min-seq-w-1l.conf -jn；
4、业务完成拔掉一节点所有数据盘；
5、一半的数据盘超时内恢复，一半超时后再恢复，触发主动修复和被动重建；
6、数据修复和重建完成后，比较内部数据一致性。

检查项:
1、步骤4、拔掉一块数据盘，业务不受影响，系统上报磁盘异常信息；
2、步骤5、持续修改写数据，立即触发数据修复，超时内恢复数据盘，系统校验数据；
3、步骤6、修复过程中，内外部数据校验一致；
4,、步骤7、修复完成后，内部数据校验一致。

"""

import os, sys
import utils_path
import common2
import common
import Lun_managerTest
import log
import get_config
import threading
import login
import time
import commands
import random
import breakdown
import ReliableTest
# import error

import env_manage_repair_test
import decorator_func
from get_config import config_parser as cp

"""初始化日志和全局变量"""
file_name = os.path.basename(__file__)
file_name = file_name[:-3]  # 获取本脚本名，去掉.py后缀
log_file_path = log.get_log_path(file_name)  # 获取日志目录，即test_cases/Log/Case_log
log.init(log_file_path, True)  # 初始化日志文件

log.info("---------------全局初始化操作-----------------")
node_ip1 = env_manage_repair_test.deploy_ips[0]
node_ip2 = env_manage_repair_test.deploy_ips[1]
client_ip1 = env_manage_repair_test.client_ips[0]
esxi_ip = env_manage_repair_test.Esxi_ips
fault_ip = random.choice(env_manage_repair_test.deploy_ips)
node_id = env_manage_repair_test.com_node.get_node_id_by_ip(fault_ip)  # 随机选取一个节点

"""获取指定节点数据盘和共享盘"""
share_disk, data_disk = env_manage_repair_test.Reliable_osan.get_share_monopoly_disk_ids(s_ip=fault_ip, node_id=node_id)
disk_ids = []
for data_disk in data_disk:
    disk_phy_id = env_manage_repair_test.Reliable_osan.get_physicalid_by_name(fault_ip, data_disk)
    disk_ids.append(disk_phy_id)
L1 = []
L2 = []
for i in range(len(disk_ids) / 2):
    disk_phy_id = disk_ids[i]  # 磁盘物理id
    print disk_phy_id
    disk_name = env_manage_repair_test.Reliable_osan.get_name_by_physicalid(fault_ip, disk_phy_id)  # 磁盘名字
    disk_uuid = env_manage_repair_test.com_disk.get_disk_uuid_by_name(node_id=node_id, disk_name=disk_name)  # 磁盘uuid
    disk_id = env_manage_repair_test.Reliable_osan.get_diskid_by_name(s_ip=fault_ip, node_id=node_id,
                                                                      disk_name=disk_name)  # 集群中的磁盘id
    L1.append("{},{},{},{}".format(disk_phy_id, disk_name, disk_uuid, disk_id))

log.info(L1)
for i in range(len(disk_ids) / 2, len(disk_ids)):
    disk_phy_id = disk_ids[i]  # 磁盘物理id
    disk_name = env_manage_repair_test.Reliable_osan.get_name_by_physicalid(fault_ip, disk_phy_id)  # 磁盘名字
    disk_uuid = env_manage_repair_test.com_disk.get_disk_uuid_by_name(node_id=node_id, disk_name=disk_name)  # 磁盘uuid
    disk_id = env_manage_repair_test.Reliable_osan.get_diskid_by_name(s_ip=fault_ip, node_id=node_id,
                                                                      disk_name=disk_name)  # 集群中的磁盘id
    L2.append("{},{},{},{}".format(disk_phy_id, disk_name, disk_uuid, disk_id))
log.info(L2)
stor_id_block = env_manage_repair_test.Lun_osan.get_storage__type_id(s_ip=fault_ip)


def iscsi_login():
    global min_seq_w
    global min_seq_r
    login.login()

    # 修改vdbench配置文件的参数值
    #seekpct = 0  # 随机
    rdpct1 = 0  # 读写比例(0是全写)
    rdpct2 = 100
    xfersize1 = cp("vdbench", "unmix_xfersize1")
    lun1 = env_manage_repair_test.Lun_osan.ls_scsi_dev(client_ip1)
    min_seq_w = env_manage_repair_test.co2_osan.gen_vdb_xml(max_range=cp("vdbench", "range"),
                                                            maxdata=cp("vdbench", "maxdata"),
                                                            thread=cp("vdbench", "threads"), lun=lun1,
                                                            xfersize=xfersize1, seekpct=cp("vdbench", "seekpct"), rdpct=rdpct1)
    min_seq_r = env_manage_repair_test.co2_osan.gen_vdb_xml(max_range=cp("vdbench", "range"),
                                                            maxdata=cp("vdbench", "maxdata"),
                                                            thread=cp("vdbench", "threads"), lun=lun1,
                                                            xfersize=xfersize1, seekpct=cp("vdbench", "seekpct"), rdpct=rdpct2)


def run_vdb_w(arg=0):
    log.info('Run task %s (%s)...' % (sys._getframe().f_code.co_name, os.getpid()))
    env_manage_repair_test.co2_osan.run_vdb(client_ip=client_ip1, vdb_xml=min_seq_w, jn_jro='jn', output=fault_ip)


def disk_error(arg=0):
    log.info('Run task %s (%s)...' % (sys._getframe().f_code.co_name, os.getpid()))
    time.sleep(int(cp("wait_time", "remove_disk")))  # 执行vdbench期间，先等待时间再开始磁盘故障的操作
    for l in L1:
        env_manage_repair_test.Reliable_osan.remove_disk(node_ip=fault_ip, disk_id=l.split(",")[0], disk_usage="DATA")

    for l in L2:
        env_manage_repair_test.Reliable_osan.remove_disk(node_ip=fault_ip, disk_id=l.split(",")[0], disk_usage="DATA")


def case():
    log.info("生成vdbench配置文件，主机端登录 ...")
    iscsi_login()
    log.info("在主机1对lun1上运行vdbench -f min-seq-w-1l.conf -jn ...")
    env_manage_repair_test.co2_osan.run_vdb(client_ip=client_ip1, vdb_xml=min_seq_w, jn_jro='jn', output=fault_ip)
    log.info("业务完成,拔掉一节点所有数据盘,一半的数据盘超时内恢复，一半超时后再恢复，触发主动修复和被动重建；")
    disk_error()

    for l in L1:
        env_manage_repair_test.Reliable_osan.insert_disk(node_ip=fault_ip, disk_id=l.split(",")[0], disk_usage="DATA")
        env_manage_repair_test.Reliable_osan.check_disk_state(node_ip=fault_ip,
                                                              disk_uuid=l.split(",")[-2],
                                                              disk_state="DISK_STATE_HEALTHY")  # 检测磁盘状态，若为HEALTHY，认为盘插回了完成
    env_manage_repair_test.Reliable_osan.run_down_disk_wait(s_ip=fault_ip,
                                                            timeout=int(cp('timeout', 'disk_timeout')))  # 设置修复的超时时间
    time.sleep(int(cp('timeout', 'disk_timeout')) /int(cp('timeout', 'unit_time'))+ 20)  # 设置等待超时的时间
    for l in L2:
        env_manage_repair_test.Reliable_osan.check_disk_state(node_ip=fault_ip,
                                                              disk_uuid=l.split(",")[-2],
                                                              disk_state="DISK_STATE_ZOMBIE")  # 检测磁盘状态，若为ZOMBIE，认为重建完成
        env_manage_repair_test.Reliable_osan.insert_disk(node_ip=fault_ip, disk_id=l.split(",")[0], disk_usage="DATA")
        env_manage_repair_test.com_disk.remove_disks_asyn(disk_ids=l.split(",")[-1])
        env_manage_repair_test.Reliable_osan.add_disks(s_ip=fault_ip, node_ids=node_id, uuid=l.split(",")[-2],
                                                       usage="DATA",
                                                       storage_id=stor_id_block)
    log.info("数据修复完成后，比较内部数据一致性 ...")
    env_manage_repair_test.co2_osan.run_vdb(client_ip=client_ip1, vdb_xml=min_seq_w, jn_jro='jro',
                                            output=node_ip1)
    env_manage_repair_test.break_down.check_bad_obj()
    env_manage_repair_test.Reliable_osan.compare_data()


def main():
    env_manage_repair_test.rel_check_before_run(filename=file_name)  # 环境检测和准备

    case()  # 用例步骤

    common.ckeck_system()  # 检查系统core

    env_manage_repair_test.clean()  # 环境清理


if __name__ == '__main__':
    common.case_main(main)  # 主函数执行入口
